import React, { useState, useRef, useEffect } from 'react';
import { Mic, Headphones, MessageSquare, GraduationCap, Square, Volume2 } from 'lucide-react';

const App = () => {
  const [status, setStatus] = useState("ready");
  const [activeModule, setActiveModule] = useState("translation");
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [nativeLang, setNativeLang] = useState("he-IL");
  const [targetLang, setTargetLang] = useState("en-US");
  const [debugLog, setDebugLog] = useState("××¢×¨×›×ª ××•×›× ×” - ×œ×—×¥ ×¢×œ ×”×ª×—×œ");
  
  const apiKey = (import.meta as any).env.VITE_API_KEY || "";
  const recognitionRef = useRef<any>(null);

  const languages = [
    { code: "he-IL", name: "×¢×‘×¨×™×ª" }, { code: "en-US", name: "English" },
    { code: "fr-FR", name: "FranÃ§ais" }, { code: "es-ES", name: "EspaÃ±ol" },
    { code: "de-DE", name: "Deutsch" }, { code: "it-IT", name: "Italiano" },
    { code: "ru-RU", name: "Ğ ÑƒÑÑĞºĞ¸Ğ¹" }, { code: "ar-SA", name: "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" },
    { code: "zh-CN", name: "ä¸­æ–‡" }, { code: "ja-JP", name: "æ—¥æœ¬èª" },
    { code: "pt-PT", name: "PortuguÃªs" }, { code: "hi-IN", name: "à¤¹à¤¿à¤¨à¥à¤¦à¥€" },
    { code: "tr-TR", name: "TÃ¼rkÃ§e" }
  ];

  // ×¤×•× ×§×¦×™×™×ª ×“×™×‘×•×¨ ×¢× ×“×’×© ×¢×œ ×§×•×œ × ×©×™
  const speak = (text: string) => {
    if (!text) return;
    window.speechSynthesis.cancel();
    const msg = new SpeechSynthesisUtterance(text);
    
    // ××¦×™××ª ×§×•×œ × ×©×™ ××ª×•×š ×”×¨×©×™××” ×”×–××™× ×” ×‘××—×©×‘ ×©×œ×š
    const voices = window.speechSynthesis.getVoices();
    const femaleVoice = voices.find(v => 
      (v.name.toLowerCase().includes('female') || v.name.toLowerCase().includes('woman') || v.name.includes('Google ×¢×‘×¨×™×ª'))
    ) || voices.find(v => v.lang.includes('he')) || voices[0];

    msg.voice = femaleVoice;
    msg.lang = 'he-IL';
    msg.pitch = 1.4; // ×”×’×‘×”×ª ×”×˜×•×Ÿ ×œ×§×•×œ × ×©×™ ×™×•×ª×¨
    msg.rate = 0.9;  // ×§×¦×‘ ×“×™×‘×•×¨ × ×¢×™×

    msg.onstart = () => setIsSpeaking(true);
    msg.onend = () => {
      setIsSpeaking(false);
      if (status === "connected") startListening();
    };
    window.speechSynthesis.speak(msg);
  };

  // ×©×œ×™×—×” ×œ-Gemini 2.0 Flash
  const getAIResponse = async (userText: string) => {
    if (!apiKey) {
      setDebugLog("âŒ ×©×’×™××”: ×—×¡×¨ API KEY ×‘-Vercel");
      return;
    }

    try {
      setDebugLog("âš¡ AI ×—×•×©×‘×ª...");
      const url = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key=${apiKey}`;
      
      const response = await fetch(url, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          contents: [{ parts: [{ text: `You are a young female assistant. Speak naturally in Hebrew. User: ${userText}` }] }]
        })
      });

      const data = await response.json();
      if (data.error) throw new Error(data.error.message);
      
      const aiText = data.candidates[0].content.parts[0].text;
      setDebugLog("âœ… AI ×¢×•× ×”");
      speak(aiText);
    } catch (e: any) {
      setDebugLog(`âŒ ×©×’×™××”: ${e.message}`);
    }
  };

  const startListening = () => {
    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    if (!SpeechRecognition) {
      setDebugLog("âŒ ×”××™×§×¨×•×¤×•×Ÿ ×œ× × ×ª××š ×‘×“×¤×“×¤×Ÿ ×–×”");
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = nativeLang;
    
    recognition.onstart = () => setDebugLog("ğŸ¤ ×× ×™ ××§×©×™×‘×” ×œ×š...");
    
    recognition.onresult = (event: any) => {
      const transcript = event.results[0][0].transcript;
      setDebugLog(`ğŸ¤ ×××¨×ª: "${transcript}"`);
      getAIResponse(transcript);
    };

    recognition.onerror = (err: any) => {
      setDebugLog(`âŒ ×©×’×™××ª ××™×§×¨×•×¤×•×Ÿ: ${err.error}`);
      if (err.error === 'not-allowed') {
        alert("×× × ××©×¨ ××ª ×”××™×§×¨×•×¤×•×Ÿ ×‘×¡×¨×’×œ ×”×›×ª×•×‘×•×ª (×¡××œ ×”×× ×¢×•×œ)");
      }
    };

    try {
      recognition.start();
      recognitionRef.current = recognition;
    } catch (e) {}
  };

  const toggleSession = () => {
    if (status === "ready") {
      setStatus("connected");
      speak("×©×œ×•×, ×× ×™ ××—×•×‘×¨×ª. ××™×š ××•×›×œ ×œ×¢×–×•×¨?");
    } else {
      setStatus("ready");
      window.speechSynthesis.cancel();
      if (recognitionRef.current) recognitionRef.current.stop();
      setDebugLog("×”××¢×¨×›×ª × ×¢×¦×¨×”");
    }
  };

  return (
    <div className="h-screen bg-slate-950 text-white flex justify-end p-4 overflow-hidden font-sans" dir="rtl">
      <div className="w-full max-w-[340px] flex flex-col gap-4">
        
        {/* ×©×“×•×ª ×©×¤×” */}
        <div className="grid grid-cols-2 gap-2">
          <div className="bg-slate-900 p-2 rounded-xl border border-slate-800">
            <span className="text-[10px] text-slate-500 block">×©×¤×ª ××</span>
            <select value={nativeLang} onChange={(e)=>setNativeLang(e.target.value)} className="w-full bg-transparent text-sm outline-none">
              {languages.map(l => <option key={l.code} value={l.code}>{l.name}</option>)}
            </select>
          </div>
          <div className="bg-slate-900 p-2 rounded-xl border border-slate-800">
            <span className="text-[10px] text-slate-500 block">×©×¤×ª ×ª×¨×’×•×</span>
            <select value={targetLang} onChange={(e)=>setTargetLang(e.target.value)} className="w-full bg-transparent text-sm outline-none">
              {languages.map(l => <option key={l.code} value={l.code}>{l.name}</option>)}
            </select>
          </div>
        </div>

        {/* ××•×“×•×œ×™× */}
        <div className="grid grid-cols-2 gap-2">
          {[
            { id: 'translation', name: '×ª×¨×’×•× ×©×™×—×”', icon: <Mic size={16}/> },
            { id: 'simultaneous', name: '×¡×™××•×œ×˜× ×™', icon: <Headphones size={16}/> },
            { id: 'chat', name: '×¦\'××˜', icon: <MessageSquare size={16}/> },
            { id: 'learning', name: '×œ×™××•×“', icon: <GraduationCap size={16}/> }
          ].map(m => (
            <button key={m.id} onClick={()=>setActiveModule(m.id)} className={`p-3 rounded-xl flex flex-col items-center gap-1 text-[10px] font-bold ${activeModule === m.id ? 'bg-indigo-600' : 'bg-slate-900 opacity-60'}`}>
              {m.icon} {m.name}
            </button>
          ))}
        </div>

        {/* ××•×•×˜××¨ ××©×” */}
        <div className="flex-1 flex items-center justify-center">
          <div className={`w-52 h-52 rounded-full p-1.5 transition-all duration-700 ${isSpeaking ? 'bg-indigo-500 shadow-2xl scale-105' : 'bg-slate-800'}`}>
            <div className="w-full h-full rounded-full overflow-hidden border-4 border-slate-950">
              <img 
                src="https://raw.githubusercontent.com/mgilady99/LINGO-AI/main/××•×•×˜××¨.jpg" 
                alt="AI Assistant" 
                className="w-full h-full object-cover"
                onError={(e) => (e.currentTarget.src = "https://www.w3schools.com/howto/img_avatar2.png")}
              />
            </div>
          </div>
        </div>

        {/* ×›×¤×ª×•×¨ ×”×¤×¢×œ×” */}
        <button 
          onClick={toggleSession}
          className={`w-full py-5 rounded-3xl font-bold text-xl flex items-center justify-center gap-3 transition-all ${status === 'ready' ? 'bg-indigo-600' : 'bg-red-600'}`}
        >
          {status === 'ready' ? <><Mic size={24} /> ×”×ª×—×œ ×©×™×—×”</> : <><Square size={24} /> ×”×¤×¡×§</>}
        </button>

        {/* ×œ×•×’ ×”×“×™×‘××’ - ×§×¨×™×˜×™ ×œ×‘×“×™×§×” ×©×œ×š */}
        <div className="bg-black/40 p-2 rounded-lg text-[10px] text-center font-mono text-indigo-300 border border-slate-800">
          {debugLog}
        </div>
      </div>
    </div>
  );
};

export default App;
